{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385fa249",
   "metadata": {},
   "source": [
    "## CB02-4 Part Six: GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8e365-87bc-4b0c-b5a7-96342c7d754b",
   "metadata": {},
   "source": [
    "### 01 PyTorch: GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1e0133-7665-446e-915c-6b5349ba7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85a2e12-e446-4076-8f94-1c9ac41df7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30ac6df-3b78-4f9c-b4bd-bd03c71579e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a1b563-46c0-4496-bd32-3abc1c7d5dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c626ca0-75f9-4a96-a1cc-406e4bb4754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b8c8b7-f099-4278-b113-83ab9b90ea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = tensor1.to('cuda')\n",
    "tensor2 = tensor2.to('cuda')\n",
    "tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99cf9b97-80a4-4c82-853a-992bdf074c42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# transfer one tensor back to CPU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtensor1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# transfer one tensor back to CPU\n",
    "tensor1 = tensor1.to('cpu')\n",
    "tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b920a9-ce8c-4211-9472-6bb174fb5c2d",
   "metadata": {},
   "source": [
    "Note: All tensors shoule be on the same device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ea86a-4bfb-485b-a6fc-ab44c741e4d6",
   "metadata": {},
   "source": [
    "### 02 Single-GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160821c9-d900-4412-a5d6-f0f6d50dfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class mlp(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            \n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_inputs, 16),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(16, num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "x_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "x_test = torch.tensor([\n",
    "[-0.8, 2.8],\n",
    "[2.6, -1.6],\n",
    "])\n",
    "y_test = torch.tensor([0, 1])\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.features = x\n",
    "        self.labels = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0] # self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = ToyDataset(x_train, y_train)\n",
    "test_dataset = ToyDataset(x_test, y_test)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(0)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True,\n",
    "    num_workers= 0,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=False,\n",
    "    num_workers= 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eef170-5a70-44f4-9f3e-dfc00fd15474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.80\n",
      "Epoch: 0, Batch: 1, Loss: 0.82\n",
      "Epoch: 1, Batch: 0, Loss: 0.30\n",
      "Epoch: 1, Batch: 1, Loss: 0.22\n",
      "Epoch: 2, Batch: 0, Loss: 0.00\n",
      "Epoch: 2, Batch: 1, Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = mlp(2, 2)\n",
    "\n",
    "'''\n",
    "1. define 'device'\n",
    "2. transfer model on to GPU\n",
    "'''\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train() # set the model to training mode: redundant for this example\n",
    "\n",
    "    for idx, (features, labels) in enumerate(train_loader):\n",
    "        '''\n",
    "        3. transfer data on to GPU\n",
    "        '''\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # clear the gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(features)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights & biases through SGD\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Batch: {idx}, Loss: {loss:.2f}')\n",
    "    \n",
    "    model.eval() # set the model to evaluation mode: redundant for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258e63b-8b95-44b4-b0b1-81754b05ee60",
   "metadata": {},
   "source": [
    "### 03 Multi-GPU Training by accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82c9b7-fbcd-4b75-aa75-d7ff2e5ae8f8",
   "metadata": {},
   "source": [
    "using 'accelerate config' to initialize '~/.cache/huggingface/accelerate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec28685-e68c-4876-b73a-e4e6bedfc9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.80\n",
      "Epoch: 0, Batch: 1, Loss: 0.82\n",
      "Epoch: 1, Batch: 0, Loss: 0.30\n",
      "Epoch: 1, Batch: 1, Loss: 0.22\n",
      "Epoch: 2, Batch: 0, Loss: 0.00\n",
      "Epoch: 2, Batch: 1, Loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen/lib/python3.12/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = mlp(2, 2)\n",
    "\n",
    "'''\n",
    "1. initialize accelerator\n",
    "'''\n",
    "accelerator = Accelerator()\n",
    "\n",
    "\n",
    "device = accelerator.device\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "'''\n",
    "2. prepare using accerator\n",
    "'''\n",
    "model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train() # set the model to training mode: redundant for this example\n",
    "\n",
    "    for idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # clear the gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(features)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        '''\n",
    "        3. backward using accelerator\n",
    "        '''\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        # update weights & biases through SGD\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch}, Batch: {idx}, Loss: {loss:.2f}')\n",
    "    \n",
    "    model.eval() # set the model to evaluation mode: redundant for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3dd1386-99f8-4410-b1e8-d70b8a886a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_gpus = list(range(torch.cuda.device_count()))\n",
    "active_gpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
