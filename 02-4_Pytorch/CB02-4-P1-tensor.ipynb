{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB02-4: Introduction to PyTorch\n",
    "Step Zero: install pytorch through [PyTorch](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.4427e-04, 1.6689e-42, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = torch.empty(3, 4)\n",
    "zeros = torch.zeros(3,4)\n",
    "ones = torch.ones(3,4)\n",
    "empty, zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
       "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
       "        [0.4556, 0.6323, 0.3489, 0.4017]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random = torch.rand(3,4) # 0-1\n",
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random2 = torch.rand(3,4)\n",
    "random2 == random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tensors from exsiting tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,3,4)\n",
    "\n",
    "empty_like = torch.empty_like(x)\n",
    "zeros_liek = torch.zeros_like(x)\n",
    "ones_like = torch.ones_like(x)\n",
    "rand_like = torch.rand_like(x)\n",
    "empty_like, empty_like.shape, zeros_liek, zeros_liek.shape, ones_like, ones_like.shape, rand_like, rand_like.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 shape (intuitive understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), tensor(24.))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,3,4) # Note: mapping relationship\n",
    "x.shape, x.sum()#.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x #  Note: mapping relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 4., 4.],\n",
       "         [4., 4., 4.]]),\n",
       " tensor([[3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.]]),\n",
       " tensor([[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(dim=2), x.sum(dim=1), x.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12., 12.]), tensor([8., 8., 8.]), tensor([6., 6., 6., 6.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(dim=(1,2)), x.sum(dim=(0,2)), x.sum(dim=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2,4)\n",
    "b = a.reshape(2,2,2)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 DataType-dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default data type\n",
    "float_x = torch.tensor([[2.5, 0.1], [1.0, 3.0]]) # default dtype is float32\n",
    "int_x = torch.tensor([2, 0]) # default dtype is int64\n",
    "float_x.dtype, int_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int16, torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((3,4), dtype=torch.int16)\n",
    "b = torch.rand((3,4), dtype=torch.float16)\n",
    "a.dtype, b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.to(torch.float32)\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 element-wise operations(same dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[2., 2.],\n",
       "         [2., 2.]]),\n",
       " tensor([[3., 3.],\n",
       "         [3., 3.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1\n",
    "twos = torch.ones(2, 2) * 2\n",
    "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
    "ones, twos, threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 4.],\n",
       "         [4., 4.]]),\n",
       " tensor([[1.4142, 1.4142],\n",
       "         [1.4142, 1.4142]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fours = twos ** 2\n",
    "sqrt_two = twos ** 0.5\n",
    "fours, sqrt_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5.],\n",
       "        [5., 5.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fives = ones + fours\n",
    "fives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10.],\n",
       "        [10., 10.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = twos * fives\n",
    "tens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5932, 0.1123, 0.1535, 0.2417],\n",
       "         [0.7262, 0.7011, 0.2038, 0.6511]]),\n",
       " tensor([[2., 2., 2., 2.]]),\n",
       " tensor([[1.1863, 0.2247, 0.3069, 0.4834],\n",
       "         [1.4525, 1.4022, 0.4076, 1.3021]]),\n",
       " tensor([[True, True, True, True],\n",
       "         [True, True, True, True]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor broadcasting: Same as numpy's boradcasting\n",
    "a = torch.rand(2,4)\n",
    "b = torch.ones(1,4) * 2\n",
    "c = a * b\n",
    "a, b, c, c == a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules:\n",
    "-   Each tensor must have at least one dimension - no empty tensors.\n",
    "-   Comparing the dimension sizes of the two tensors, *going from last\n",
    "    to first:*\n",
    "    -   Each dimension must be equal, *or*\n",
    "    -   One of the dimensions must be of size 1, *or*\n",
    "    -   The dimension does not exist in one of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boradcasting examples:\n",
    "a = torch.ones(4,3,2)\n",
    "\n",
    "b = torch.rand(3,2) #(4,3,2)\n",
    "b_ = torch.rand(1,3,2) #(4,3,2)\n",
    "\n",
    "c = torch.rand(4,3) # #(4,3,2)\n",
    "c_ = torch.rand(4,3,1) #(4,3,2)\n",
    "\n",
    "d = torch.rand(1,2) #(4,3,2)\n",
    "d_ = torch.rand(1,1,2) #(4,3,2)\n",
    "\n",
    "e = torch.rand(4,2) #(4,3,2)\n",
    "e_ = torch.rand(4,1,2) #(4,3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a * c error\n",
      "a * e error\n"
     ]
    }
   ],
   "source": [
    "# a * X\n",
    "try: a * b \n",
    "except: print(\"a * b error\")\n",
    "\n",
    "try: a * b_\n",
    "except: print(\"a * b_ error\")\n",
    "\n",
    "try: a * c\n",
    "except: print(\"a * c error\")\n",
    "\n",
    "try: a * c_\n",
    "except: print(\"a * c_ error\")\n",
    "\n",
    "try: a * d\n",
    "except: print(\"a * d error\")\n",
    "\n",
    "try: a * d_\n",
    "except: print(\"a * d_ error\")\n",
    "\n",
    "try: a * e\n",
    "except: print(\"a * e error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06 In-place Operations\n",
    "Most binary operations on tensors will return a third, new tensor. When\n",
    "we say `c = a * b` (where `a` and `b` are tensors), the new tensor `c`\n",
    "will occupy a region of memory distinct from the other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8415, 0.8415],\n",
       "        [0.8415, 0.8415]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(2,2)\n",
    "print(a)\n",
    "a.sin_()\n",
    "a.cos()\n",
    "# torch.sin_(a) # torch.sin(a)\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more exaplmes\n",
    "a = torch.ones(2,2)\n",
    "b = torch.ones(2,2)\n",
    "a.add(b)\n",
    "a.sub(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.add_(b)\n",
    "a == c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. Three Kinds of  Muls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,4)\n",
    "b = torch.ones(3,4) * 2\n",
    "a, b\n",
    "# torch.matmul(a, b.T, out=c)\n",
    "# torch.mul(a, b, out=d)\n",
    "# e = torch.empty(1)\n",
    "# torch.dot(a, b.T, out=e)\n",
    "# c, d, e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]]),\n",
       " tensor([[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]]),\n",
       " tensor([[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise mul: Hamamard product\n",
    "a * b == torch.mul(a, b), a * b == a.mul(b), a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product\n",
    "a.reshape(-1).dot(b.reshape(-1)) # == (a*b).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]],\n",
       "\n",
       "        [[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]],\n",
       "\n",
       "        [[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "a = torch.ones(3,3,4)\n",
    "b = torch.ones(1,4,5)\n",
    "\n",
    "torch.matmul(a, b)\n",
    "\n",
    "#note: torch.mm, torch.mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 Copying Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[0., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assingment does not copy: just a label of the same memory\n",
    "a =  torch.ones(3,4)\n",
    "b = a\n",
    "a[0][0] = 0\n",
    "b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  torch.zeros(3,4)\n",
    "b = a.clone()\n",
    "a[0][0] = 1\n",
    "a, b\n",
    "# Note: if source tensor(a) has autograd, so will the clone(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you *don't* want the cloned copy\n",
    "of your source tensor to track gradients - performance is improved with\n",
    "autograd's history tracking turned off. For this, you can use the\n",
    "`.detach()` method on the source tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]], requires_grad=True),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]], grad_fn=<CloneBackward0>),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,4, requires_grad=True)\n",
    "\n",
    "b = a.clone()\n",
    "\n",
    "c = a.detach().clone()\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 Squeeze & Unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 10])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(10, 10, 10)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 10, 10]),\n",
       " torch.Size([10, 1, 10, 10]),\n",
       " torch.Size([10, 10, 1, 10]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add one dimension\n",
    "x.unsqueeze(0).shape, x.unsqueeze(1).shape, x.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10, 10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =  x.unsqueeze(0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10, 10]),\n",
       " torch.Size([1, 10, 10, 10]),\n",
       " torch.Size([1, 10, 10, 10]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze(0).shape, y.squeeze(1).shape, y.squeeze(2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(2,3,4)\n",
    "x.unsqueeze(0).shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze_(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze_(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 NumPy Birdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.]]),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "nd_array = np.ones((2,2)) # default: float64\n",
    "\n",
    "tensor = torch.from_numpy(nd_array).to(torch.float32)\n",
    "\n",
    "nd_array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " array([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]], dtype=float32))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(2,3,4)\n",
    "nd_array = tensor.numpy()\n",
    "type(nd_array), nd_array   \n",
    "#Note: They are using the same memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
